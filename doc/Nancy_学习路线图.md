# Nancy 机器人 — 强化学习路线图

> 目标：4 周内掌握所有必要知识，能读懂 Columbia Emo 论文并独立实现  
> 前提：已有嵌入式基础、Python 基础、吴恩达课程前半部分  
> 强度：每天 4-6 小时学习

---

## 知识全景

```
Nancy 项目 = 4 大模块

① 深度学习基础        看懂论文、理解模型、会训练
② FACS + 面部感知     项目的"语言"，贯穿软硬件
③ 机械结构设计        连杆、运动学、CAD、硅胶皮肤
④ 系统整合            Jetson + 舵机 + ROS + 实时控制
```

---

## 第 1 周：深度学习基石与框架过渡（Coursera C4+C5 → PyTorch）

> **设计思路补充**：作为底层/嵌入式开发者，你的学习不能走马观花。吴恩达的 Coursera 专项课程（C4 卷积神经网络、C5 序列模型）中包含极具价值的底层作业。与其单纯看视频，不如挑出**最核心的几周作业**认真跑通。学完底层理论后，再于周末平滑切换至工业部署首选的 PyTorch 框架。

### Task 1：CNN 底层逻辑（吴恩达 C4 Week 1）[x]

| 时间 | 内容                                           | 核心输出/作业                                                                                     |
| ---- | ---------------------------------------------- | ------------------------------------------------------------------------------------------------- |
| 上午 | 理论：卷积层、步长、Padding、池化层            | [YouTube Playlist: CNN](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF) |
| 下午 | 理论：为什么要用卷机网络而不是全连接？         | 同上                                                                                              |
| 晚上 | **实战**：[已完成✅] Numpy 手推卷积前/反向传播 | Coursera 作业: `Convolution_model_Step_by_Step_v2a.ipynb`                                         |

**里程碑**：理解由图像张量进入，经过滤波器提取出特征图的数学本质。

### Task 2：经典视觉架构与其底层思想（吴恩达 C4 Week 2）[x]

| 时间 | 内容                                | 核心输出/作业                                                              |
| ---- | ----------------------------------- | -------------------------------------------------------------------------- |
| 上午 | 理论：LeNet-5, AlexNet, VGG-16      | 感受感受野和深度的作用                                                     |
| 下午 | 理论：ResNet（残差网络）、1x1 卷积  | 明白为什么残差连接（Add）能防止梯度消失，让网络能做得很深                  |
| 晚上 | **复盘**：跳过全英文 Keras 代码作业 | 重点理解残差网络与 1x1 卷积的原理即可（省下精力留给后面的 PyTorch 实战）。 |

### Task 3：人脸识别背后的核心算法（绝对不能跳过的 C4 Week 4）[x]

> **为何重要**：之前错误地以为“人脸识别”仅仅是解锁手机的工具，所以建议你跳过。但细看你的**两篇顶刊论文**，里面充满了将图片映射到“隐空间 (Latent Space)” 并在隐向量之间计算距离 `||L't - Li||` 的操作 (VAE/Wav2Lip)。吴恩达这一周讲的 Siamese 网络和 Triplet Loss，**正是这些隐向量距离计算的绝对基础！没学这个，你根本看不懂论文 2 的数学推导。**

| 时间 | 内容                                           | 核心输出/作业                                                  |
| ---- | ---------------------------------------------- | -------------------------------------------------------------- |
| 上午 | 理论：One-Shot 学习与 Siamese 网络架构         | 懂了一张图如何被网络“压缩”成一个 Vector（向量映射）            |
| 下午 | 理论：Triplet Loss（三元组损失函数）           | 学会网络是如何评判两张人脸（或两种表情）在隐空间里“有多像”的   |
| 晚上 | 理论扩展：神经风格迁移 (Neural Style Transfer) | 了解如何将内容（人的面部动作）与风格（特征本身）进行分离和匹配 |

### Task 4：时间序列模型的记忆与进化（C5 Week 1 & 3）

| 时间 | 内容                                      | 核心输出/作业                                                                                                 |
| ---- | ----------------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| 上午 | 理论：为什么要用序列模型？RNN 基础架构    | [YouTube Playlist: Sequence Models](https://www.youtube.com/playlist?list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6) |
| 下午 | 理论：GRU 与 LSTM 的内部逻辑门            | 重点理解 C（记忆细胞）和 H（隐藏状态）是如何随时间传递的                                                      |
| 晚上 | 进阶篇：Attention 机制与 Transformer 概念 | 懂它为什么能解决长时序列的遗忘问题，看懂 Nancy 动作推演的最后一张图                                           |

### Task 5：武器库切换——PyTorch 基础（张量与求导）[x]

_此时你已通过 Coursera 掌握了理论和参数概念，现在正式全面转向 PyTorch_

| 时间 | 内容                                        | 核心输出/作业                                                               |
| ---- | ------------------------------------------- | --------------------------------------------------------------------------- |
| 上午 | Tensor 运算与 CPU/GPU (`.cuda()`) 内存流向  | [小土堆 PyTorch 教程](https://www.bilibili.com/video/BV1hE411t7RN) 前端部分 |
| 下午 | 核心引擎：Autograd（自动求导）、nn.Module   | 官方文档或教程，对比 PyTorch 自动算梯度和 Task 1 你手写 Numpy 梯度的区别    |
| 晚上 | 动手：PyTorch 搭建双层全连接网络(MLP)作回归 | 跑通“定义网络 - 清空梯度 - 反向传播 - 更新权重”的训练闭环                   |

### Task 6：PyTorch 数据流与视觉实战

| 时间 | 内容                                      | 核心输出/作业                                                 |
| ---- | ----------------------------------------- | ------------------------------------------------------------- |
| 上午 | 数据管道：自定义 Dataset 和 DataLoader    | 学习如何把硬盘上的假数据打包成 Batch 送进网络                 |
| 下午 | 使用 `nn.Conv2d` 与 `nn.MaxPool2d`搭网络  | 把 C4 学到的理论变成 PyTorch 里的实际图纸                     |
| 晚上 | 动手：跑通 MNIST 或 CIFAR 10 标准分类流程 | 完成一次标准化的端到端训练迭代记录 (Loss 下降，Accuracy 提升) |

### Task 7：生成式模型基石：AE 与 变分自编码器(VAE)

> **为何重要**：哥大第二篇论文(唇同步)的核心，是把机器人乱动的视频帧压缩成 16维隐向量，强行让它和合成人脸对齐。这就需要理解连续的概率分布和 KL散度。不学 VAE，这一步就会像看天书。

| 时间 | 内容                                             | 核心输出/作业                                                                 |
| ---- | ------------------------------------------------ | ----------------------------------------------------------------------------- |
| 上午 | 理论：Autoencoder(自动编码器) 的重建误差 (MSE)   | [李宏毅机器学习：Auto-encoder](https://www.youtube.com/watch?v=Rdpbnd0pCiI)   |
| 下午 | 理论：VAE 为什么要“变分”？引入 $\mu$ 和 $\sigma$ | [李宏毅机器学习：VAE (含KL散度)](https://www.youtube.com/watch?v=YruFM7GuJTE) |
| 晚上 | **动手**：用 PyTorch 徒手撸一个极简 VAE          | 跑通一个带 KL 惩罚项的 Loss 函数，打印出连续的隐空间采样                      |

### Task 8：注意力机制的究极体：Transformer 架构 (切换为李沐 D2L)

> **为何重要**：普通的 RNN/LSTM 在长句子序列里还是会遗忘，而第二篇论文为了保证唇部电机命令绝对不抖动，用的是 FAT (Facial Action Transformer)。你必须彻底搞懂 Self-Attention 和 Transformer Decoder 的底层矩阵乘法。相比于纯 PPT 讲解，李沐老师的代码级拆解对程序员绝对更友好。

| 时间 | 内容                                               | 核心输出/作业                                                                       |
| ---- | -------------------------------------------------- | ----------------------------------------------------------------------------------- |
| 上午 | 理论与代码：注意力机制 / 自注意力 (Self-Attention) | 阅读/观看 D2L 第10章: `10.1-10.5 自注意力机制`。弄懂 Q, K, V 矩阵的实际代码和形状。 |
| 下午 | 理论与代码：Transformer Encoder 与 Decoder 架构    | 阅读/观看 D2L 第10章: `10.6-10.7 Transformer`。包括位置编码(PE)如何在代码里生成。   |
| 晚上 | **动手跑图纸**：在电脑上跑通 D2L 10.7 的全量源码   | 这个作业取代了纸上推导，直接照着 D2L 书本敲一次 Transformer 的前向传播即可通透！    |

---

## 第 2 周：顶刊论文拆解与面部追踪实战

> **调研修正**：Columbia Emo 机器人的核心不是简单的“看到表情再做表情”，而是**预测（Anticipating）**，能提前 840 毫秒预测人类情绪；并且它的运动模型是通过**对镜自我学习（Self-modeling / VAE 隐空间对齐）**建立的逆运动网络。这周以此为目标重新打造。

### Task 9：精读 Columbia Emo 核心论文 (视觉预测+唇同步)

| 时间 | 内容                                               | 资源与任务                                                                                                         |
| ---- | -------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| 上午 | 研读 2024 年 _Science Robotics_ Emo 论文背景与架构 | 精读 Paper 1 (表情共表达)，重点钻研 **预测网络（Anticipation Network）**，懂它如何提取前置视频帧特征。             |
| 下午 | 研读 2026/24 年唇同步顶刊核心算法                  | 精读 Paper 2 (唇同步)，对照你昨天学的 VAE，**彻底搞懂隐向量 L't 与 Li 的最近邻匹配算法**，以及 Closure Loss 公式。 |
| 晚上 | 重点钻研：**对镜自学习（Motor Babbling）**         | 弄懂 Emo 如何看着镜子胡乱动舵机生成特征配对，从而自己学会“哪个舵机拉扯会导致哪里的硅胶运动”。                      |

### Task 10：FACS 面部动作编码系统

| 时间 | 内容                                       | 资源                                                                        |
| ---- | ------------------------------------------ | --------------------------------------------------------------------------- |
| 上午 | FACS 基础：什么是 AU（Action Unit）及强度  | [FACS Wikipedia](https://en.wikipedia.org/wiki/Facial_Action_Coding_System) |
| 下午 | 熟悉核心 AU：皱眉(AU4)、微笑(AU12)、睁眼等 | 了解人类表皮肌肉是如何收缩引起表皮形变的，这是控制软体硅胶脸的基础。        |
| 晚上 | 实践：对着镜子，把自己的脸当成机器人       | 体验一下你的表情是由多少块面部肌肉协同拉扯（协同舵机）完成的。              |

### Task 11-12：面部关键点与微表情追踪 (MediaPipe)

| 时间 | 内容                                         | 资源                                                                                     |
| ---- | -------------------------------------------- | ---------------------------------------------------------------------------------------- |
| 上午 | MediaPipe Face Mesh 安装与测试               | Emo 机器人是在眼睛里安装摄像头。你也先用电脑摄像头起步抓人脸。                           |
| 下午 | 理解 468 个关键点的三维空间（XYZ）分布       | [Google MediaPipe 官方文档](https://google.github.io/mediapipe/solutions/face_mesh.html) |
| 晚上 | 写代码：提取瞳孔间距纠正尺度，计算微表情趋势 | 提取嘴角的拉伸速度追踪微笑趋势，提取眼轮匝肌距追踪皱眉趋势。保存数据集。                 |

### Task 12：建立你自己的表情捕捉数据管道

| 时间 | 内容                                                                   |
| ---- | ---------------------------------------------------------------------- |
| 上午 | 使用 OpenCV 录制你自己的脸部表情（模拟人类互动数据集）                 |
| 下午 | 写 Python 脚本自动跑批你的视频，抽取出连续时间帧（如 30fps）的特征张量 |
| 晚上 | 将提取的数据打包保存为 `.npy` 矩阵文件，为下周深度学习做准备           |

---

## 第 3 周：硬核机械与电子系统（双核机构复现）

> **结构修正**：结合两篇论文，机器人的核心硬件具有极大挑战：**26 个高密度 DOF**（其中 10 个专注唇部），且突破了传统纯拉线的限制，实现了**推/拉双向驱动**与**欠驱动顺应关节**；皮肤采用**磁性快拆结构**。这周是你的主战场！

### Task 13-14：10 DOF 仿生唇部与推拉双向机构设计

| 时间 | 内容                               | 资源与任务                                                                                               |
| ---- | ---------------------------------- | -------------------------------------------------------------------------------------------------------- |
| 上午 | 研读论文的硬件补充材料 (Hardware)  | 重点看 10-DOF 口部结构：左右嘴角(各2DOF，控制前突/回缩)、上唇(3DOF，下降外翻)、下唇(2DOF，抬升外翻)。    |
| 下午 | **双向推/拉（Push-Pull）机构分析** | 传统线缆只能拉。你需要设计刚性/半刚性连杆结合柔性枢纽，使得电机既能把嘴唇扯开，也能撅起来（Puckering）。 |
| 晚上 | Fusion 360 建模实战                | 设计一个具有磁铁锚点（Magnetic quick-release connectors）的唇部独立驱动单元雏形，准备 3D 打印测试。      |

### Task 15：眼球深度的秘密与高频总线通信

| 时间 | 内容                                                                                                                                      |
| ---- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| 上午 | **眼部硬件视角**：设计一个 2 自由度眼球云台，中心必须留通孔放置微型广角摄像头。这是实现目光接触（Eye Contact）的绝对前提。                |
| 下午 | 思考 26 个微型舵机的布局（空间几何折叠）与安装背板设计。                                                                                  |
| 晚上 | **电子总线提速**：研究双 PCA9685 级联架构。修改 Jetson I2C 波特率（提权至 400kHz 或更高级别），确保 26 个通道的高频同步刷新没有任何抖动。 |

### Task 16-17：硅胶皮肤翻模与"磁吸快拆"工艺

| 时间 | 内容                                                                                             |
| ---- | ------------------------------------------------------------------------------------------------ |
| 上午 | 学习铂金硅胶（如 Ecoflex/Dragon Skin）的调配与真空除泡工艺。                                     |
| 下午 | **锚点植入工艺**：如何在硅胶固化前，将微型钕磁铁（Ø3-5mm）精准埋入对应脸上 26 个肌肉节点的位置？ |
| 晚上 | 组装你的第一个测试单元：电机 + 连杆 + 磁吸扣 + 单块硅胶，并跑通第一波平滑缓入缓出代码。          |

### Task 18：Motor Babbling（电机自主探索）数据采集

| 时间 | 内容                                                                                                                                                                                                                  |
| ---- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 全天 | **极度重要的数据集建立**：写一段脚本，让组装好的面部系统进行 "Motor Babbling"（随机胡乱发送舵机组合指令），同时用前置摄像头录下形变后的脸。生成至少数千帧 `[视频帧, 电机指令]` 的配对矩阵。这是下周自监督学习的命脉。 |

---

## 第 4 周：前沿双模型融合（视觉共情 + 音频唇语）

> **冲刺目标**：在边缘计算端（Jetson），融合 **Paper 1 的视觉表情预测（共表达）** 与 **Paper 2 的音频驱动唇步同步（VAE+FAT）**，打造终极拟人内核。

### Task 19-20：管线 A —— 视觉表情共表达（Anticipation & Inverse Kinematics）

| 时间    | 内容                                                                                                                                                                               |
| ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Task 19 | **逆运动学自模型训练**：拿 Task 18 录制的 Motor Babbling 数据，训练一个极简的特征解码器。输入是想要的表情特征，输出是 26 个舵机的目标拉力值。这一步彻底跳过复杂的物理建模。        |
| Task 20 | **意图预测 (Anticipation) 网络搭建**：复现论文核心因果推理模型。从人类对话视频中，训练网络通过人脸微表情，提前 **840 毫秒** 预测出目标表情（比如察觉到别人要笑了，提取发笑趋势）。 |

### Task 21-23：管线 B —— 逼真唇部同步（Learn Realistic Lip Motions）

| 时间    | 内容                                                                                                                                                                                                |
| ------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Task 21 | **理解 Wav2Lip 与 VAE 域自适应**：了解如何利用开源的 Wav2Lip 将音频转为 2D 目标合成图像。然后使用 PyTorch 搭建一个变分自编码器 (VAE)，把摄像头真实的机器人脸和合成脸，映射到同一个 **16维隐空间**。 |
| Task 22 | **面部动作 Transformer (FAT) 建模**：唇同步不能发生抖动。用 Transformer Encoder-Decoder 结构，输入前一帧的电机动作和当前隐空间向量，输出极致平滑的当前电机指令。                                    |
| Task 23 | **加闭唇惩罚 (Closure Loss)**：重点攻克 "b/p/m" 这类爆破双唇音。修改损失函数，当遇到双唇音特征时，强制要求上下唇的机械距必须为零合拢（这是避免"假唱感"的核心秘密）。                                |

### Task 24-26：系统整合与端侧部署 (Jetson)

| 时间    | 内容                                                                                                                                                                                     |
| ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Task 24 | **大一统并发架构设计**：<br>- 线程 1：麦克风监听 -> TTS/Wav2Lip推理 -> VAE+FAT -> 唇部 10 舵机指令<br>- 线程 2：眼部摄像头感知 -> Anticipation预测 -> 逆运动网络 -> 脸部其他 16 舵机指令 |
| Task 25 | **推理加速部署 (TensorRT)**：将庞大的 Transformer 和预测网络分别转为 ONNX 并由 Jetson 的 GPU 加速编译为 TensorRT 引擎，压榨极致延迟保证 840ms 半秒级的身心合一。                         |
| Task 26 | **实机对话闭环**：接入 LLM（如 ChatGPT API），进行全流程对话测试：语音打招呼 -> LLM思考生成文本 -> Edge-TTS 转语音 -> Robot 并发进行脸部微表情调整及同步唇语发音！                       |

### Task 27-28：技术复盘与迭代

- **验收测试**：测试 11 种多语言的唇部泛化能力（论文证明仅用英语训练也能泛化到中/日/法等）。
- **难点梳理**：系统录制演示视频。总结硅胶弹性的热衰减、Wav2Lip 推理延迟带来的滞后等问题。
- **展望规划**：规划下一代底层硬件系统及多模态端到端模型的预研。

---

## 资源汇总

### 视频课程 (优先推荐)

| 资源                  | 内容                   | 时长 | 链接                                                                                                                                                        |
| --------------------- | ---------------------- | ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 吴恩达 CNN            | 卷积神经网络           | ~10h | [B站中英字幕版](https://www.bilibili.com/video/BV1FT4y1E74V) / [YouTube Playlist](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF) |
| 吴恩达 序列模型       | RNN/LSTM/Attention     | ~10h | [B站中英字幕版](https://www.bilibili.com/video/BV12E411a7Xn) / [YouTube Playlist](https://www.youtube.com/playlist?list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6) |
| 李宏毅 2021/2022      | Autoencoder & VAE      | ~3h  | [B站: Auto-encoder 基础](https://www.bilibili.com/video/BV1Wv411h7kN?p=72) / [B站: VAE](https://www.bilibili.com/video/BV1Wv411h7kN?p=76)                   |
| 动手学深度学习 (李沐) | Transformer (配书必学) | ~4h  | [B站: D2L 注意力机制与Transformer (66-68集)](https://www.bilibili.com/video/BV1Mv411r7eb?p=66)                                                              |
| 小土堆 PyTorch        | PyTorch 入门实战       | ~5h  | [B站教程 (极度详细适合新手)](https://www.bilibili.com/video/BV1hE411t7RN)                                                                                   |

### 文本与图文资料 (便于速查)

| 资源                     | 内容                                     | 链接                                                                                                               |
| ------------------------ | ---------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| **PyTorch 中文速通教程** | **非常推荐！最符合 Task 5/6 的实战骨架** | [PyTorch 快速入门指南 (官方中文翻译版)](https://pytorch-cn.com/tutorials/beginner/basics/quickstart_tutorial.html) |
| 动手学深度学习 (李沐)    | 图文并茂，含数学推导与代码               | [Dive into Deep Learning (中文版)](https://zh.v2.d2l.ai/) _强烈推荐作为案头书翻阅_                                 |
| 3Blue1Brown (图文版)     | 神经网络可视化数学推导                   | [3B1B Neural Networks Text Articles](https://www.3blue1brown.com/topics/neural-networks)                           |
| Transformer 图解 (经典)  | 直观理解 Q/K/V 运算流程                  | [The Illustrated Transformer (中文翻译版)](https://jalammar.github.io/illustrated-transformer/)                    |

### 工具 & 库

| 工具              | 用途             | 安装                                                                      |
| ----------------- | ---------------- | ------------------------------------------------------------------------- |
| PyTorch           | 深度学习框架     | `pip install torch torchvision`                                           |
| MediaPipe         | 面部关键点检测   | `pip install mediapipe`                                                   |
| OpenFace          | AU 检测 (备选)   | [GitHub Releases](https://github.com/TadasBaltrusaitis/OpenFace/releases) |
| OpenCV            | 图像处理         | `pip install opencv-python`                                               |
| adafruit-servokit | PCA9685 舵机控制 | `pip install adafruit-circuitpython-servokit`                             |
| Fusion360         | CAD 建模         | [免费下载](https://www.autodesk.com/products/fusion-360/personal)         |

### 论文原文与开源数据

| 资源                                                                                 | 说明                     |
| ------------------------------------------------------------------------------------ | ------------------------ |
| [Emo Robot (2024)](https://www.creativemachineslab.com/emo.html)                     | 共表达论文主页 + 视频    |
| [Realistic Lip Motions (2026)](https://doi.org/10.5281/zenodo.17804235)              | 唇同步网络代码开源地址   |
| [Wav2Lip 开源实现](https://github.com/Rudrabha/Wav2Lip)                              | 音频生成虚拟人脸源码参考 |
| [FACS Manual (Wikipedia)](https://en.wikipedia.org/wiki/Facial_Action_Coding_System) | AU 面部动作神经编码参考  |

---

## 每日检查清单

```
□ 今天学了什么新概念？能用自己的话解释吗？
□ 今天写了代码吗？能跑起来吗？
□ 这个知识和 Nancy 项目的哪个环节有关？
□ 还有什么不懂的？记录下来明天解决。
```

---

## 里程碑

| 时间点  | 里程碑                        | 验证方法                 |
| ------- | ----------------------------- | ------------------------ |
| Task 7  | ✅ 能写 PyTorch 训练循环      | 不看资料写出完整训练代码 |
| Task 11 | ✅ 对着摄像头实时输出 AU 值   | MediaPipe 代码跑起来     |
| Task 14 | ✅ 能画出论文完整系统框图     | 手绘/Excalidraw          |
| Task 18 | ✅ Fusion360 画出一个舵机支架 | 导出 STL 打印            |
| Task 21 | ✅ 摄像头→AU→舵机 跑通        | 对着摄像头，舵机动起来   |
| Task 28 | ✅ 完整 V1 演示               | 录一个演示视频           |
